{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import imageio\n",
    "import keras \n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Activation, BatchNormalization, Flatten, Dropout\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot single image\n",
    "def plotBart(image_location):\n",
    "    content_image = imageio.imread(image_location)\n",
    "    imshow(content_image)\n",
    "    return\n",
    "\n",
    "image_location = \"./the-simpsons-characters-dataset/simpsons_dataset/bart_simpson/pic_0000.jpg\"\n",
    "#plotBart(image_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global varialbes\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 1\n",
    "FC_LAYERS = [1024, 1024, 256, 32] # Fully connected layers\n",
    "DROPOUT = 0.5 # Dropout rate = 1- keep_prob\n",
    "LR = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    train_dir = './simpsons_dataset_large/train' # To change\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,  \n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.3, \n",
    "        rotation_range=30, \n",
    "        width_shift_range=0.2, \n",
    "        height_shift_range=0.2, \n",
    "        shear_range=0.2,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                        target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), \n",
    "                                                        batch_size=BATCH_SIZE, \n",
    "                                                        shuffle = True)\n",
    "    return train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dev_data():\n",
    "    dev_dir = './simpsons_dataset_large/dev' # To change\n",
    "\n",
    "    dev_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    dev_generator = dev_datagen.flow_from_directory(dev_dir, \n",
    "                                                    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), \n",
    "                                                    batch_size=BATCH_SIZE, \n",
    "                                                    shuffle = True)\n",
    "    \n",
    "    return dev_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    test_dir = './simpsons_dataset_large/test' # To change\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(test_dir, \n",
    "                                                      target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), \n",
    "                                                      batch_size=BATCH_SIZE, \n",
    "                                                      shuffle = False)\n",
    "    \n",
    "    return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_generator = load_train_data()\n",
    "dev_generator = load_dev_data()\n",
    "test_generator = load_test_data()\n",
    "\n",
    "label_map = train_generator.class_indices\n",
    "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
    "\n",
    "num_classes = len(label_map)\n",
    "print (str(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(base_model): \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    for fc in FC_LAYERS:\n",
    "        # New FC layer\n",
    "        x = Dense(fc, activation='relu')(x) \n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(rate=DROPOUT)(x)\n",
    "\n",
    "    # New softmax layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x) \n",
    "    \n",
    "    model_built = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model_built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_using_VGG16():\n",
    "    # Change this to use different trained models\n",
    "    base_model = VGG16(weights='imagenet', \n",
    "                       include_top=False, # Wonâ€™t be keeping the Fully-Connected (FC) layers at the end of the mode\n",
    "                       input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "\n",
    "    model = build_model(base_model)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model_using_VGG16()\n",
    "\n",
    "# #Compile model\n",
    "# opt = Adam(lr=LR)\n",
    "# #opt = SGD(lr=LR)\n",
    "# model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model = load_model(\"./model.h5\")\n",
    "print(K.get_value(model.optimizer.lr))\n",
    "# To set learning rate\n",
    "K.set_value(model.optimizer.lr, 0.00001)\n",
    "print(K.get_value(model.optimizer.lr))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and dev loss & accuracy\n",
    "def plot_training_and_dev(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'rs')\n",
    "    plt.plot(epochs, val_acc, 'g^')\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'rs')\n",
    "    plt.plot(epochs, val_loss, 'g^')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig('acc_vs_epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(predictions):\n",
    "    labels = [label_map[i] for i in range(len(label_map))]\n",
    "    y_true = [label_map[i] for i in test_generator.classes]\n",
    "    y_pred = [label_map[i] for i in predictions]\n",
    "    \n",
    "    report = classification_report(y_true, y_pred, labels=labels)\n",
    "    print (str(report))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels)\n",
    "    \n",
    "    #print(cm)\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    #plt.title('Confusion matrix of the classifier')\n",
    "    fig.colorbar(cax)\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, labels, rotation=90)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    # Checkpoints\n",
    "    checkpoint_filepath = \"./model.h5\"\n",
    "    checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Train model using train and dev data\n",
    "    history = model.fit_generator(train_generator, \n",
    "                                  steps_per_epoch=train_generator.n // train_generator.batch_size, \n",
    "                                  validation_data=dev_generator, \n",
    "                                  validation_steps=dev_generator.n // dev_generator.batch_size, \n",
    "                                  epochs=NUM_EPOCHS, \n",
    "                                  workers=100, \n",
    "                                  shuffle=True,\n",
    "                                  callbacks=callbacks_list)\n",
    "\n",
    "    # Plot training and dev: loss and accuracy\n",
    "    plot_training_and_dev(history)\n",
    "    \n",
    "    # Predict test data\n",
    "    predictions = model.predict_generator(test_generator, \n",
    "                                          steps = test_generator.n // test_generator.batch_size)\n",
    "    predictions = np.argmax(predictions, axis=-1) #multiple categories     \n",
    "    show_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
